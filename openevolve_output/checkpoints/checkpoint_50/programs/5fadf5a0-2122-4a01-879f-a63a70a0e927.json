{"id": "5fadf5a0-2122-4a01-879f-a63a70a0e927", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute both ratios for balanced decision\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using both ratios\n    if r_ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the larger ratio as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "ba942b6e-3b40-4a70-a62e-448b15f17e57", "generation": 2, "timestamp": 1768219652.222514, "iteration_found": 47, "metrics": {"combined_score": 0.08292338142301477, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08292338142301477}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "0.028s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 71 lines with 72 lines", "parent_metrics": {"combined_score": 0.07655058478400498, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07655058478400498}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "0.009s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in numerical optimization and ADMM algorithms.\n\nYour task is to improve the function update_rho(rho, k, r_norm, s_norm, ...)\nused to adaptively update the ADMM penalty parameter.\n\nGoals:\n- Achieve faster convergence (fewer ADMM iterations)\n- Maintain numerical stability (avoid oscillating rho)\n- Balance primal and dual residuals efficiently\n\nConstraints:\n- You may ONLY modify the body of update_rho and helper functions in initial_program.py\n- The function signature and return types must remain unchanged\n- The code must be deterministic and numerically safe\n\nHints:\n- Consider using ratios or log-ratios of r_norm and s_norm\n- Early iterations may benefit from aggressive updates\n- Later iterations should favor stability\n- Piecewise or stateful strategies are allowed\n", "user": "# Current Program Information\n- Fitness: 0.0766\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0829 \u2192 0.0766. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 71 lines with 64 lines\nChange 2: Replace 15 lines with \n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.012s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 45 lines with 64 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.045s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 75 lines with 92 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292794781575066}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.016s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    # Also, if residuals are large, be more sensitive\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration and residual scale\n    if k < 5:\n        # Very early: very aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    # Use a smoother approach: compute a weighted decision\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # The factor should be between base_factor and 1.0, but we want >1\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292794781575066}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.016s'})\n\n### Program 2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Adjust factor with diminishing component\n    # We want to reduce the factor as iterations increase\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.045s'})\n\n### Program 3 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.012s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute both ratios for balanced decision\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using both ratios\n    if r_ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the larger ratio as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor with diminishing component\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using the standard mu threshold\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0829, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    # Also, if residuals are large, be more sensitive\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration and residual scale\n    if k < 5:\n        # Very early: very aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    # Use a smoother approach: compute a weighted decision\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # The factor should be between base_factor and 1.0, but we want >1\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0761, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Adjust mu based on iteration: start more permissive, become stricter\n    # For early iterations (k < 10), use a larger threshold to allow exploration\n    if k < 10:\n        dynamic_mu = mu * 2.0\n    else:\n        # Gradually tighten to mu by iteration 50\n        dynamic_mu = mu * (1.0 + np.exp(-0.1 * (k - 10)))\n    \n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration and ratio\n    # Early iterations: more aggressive (up to 2.0), later: more conservative (up to 1.3)\n    if k < 10:\n        base_factor = 1.8\n    elif k < 30:\n        base_factor = 1.5\n    else:\n        base_factor = 1.2\n    \n    # Adjust factor based on how far ratio is from 1, but bounded\n    # Use a smooth function: factor = base_factor + 0.1 * min(|log(ratio)|, 3.0)\n    # This makes updates larger when residuals are more imbalanced\n    if ratio > 0:\n        log_ratio = np.log(ratio)\n        adjustment = 0.1 * min(abs(log_ratio), 3.0)\n    else:\n        adjustment = 0.0\n    factor = base_factor + adjustment\n    \n    # Clip factor to reasonable bounds\n    factor = min(max(factor, 1.05), 2.5)\n    \n    # Update decision\n    if ratio > dynamic_mu:\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > dynamic_mu:\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Ensure rho stays within bounds\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    return new_rho, t, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 3 (Score: 0.0826, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early (smaller threshold)\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute both ratios\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    t = tau(k, c, p)\n    # Update logic\n    if r_ratio > effective_mu:\n        factor = max(base_factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        factor = max(base_factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Bound rho for numerical stability\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Auxiliary value\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef compute_adjustment_factor(ratio, k, base=0.85):\n    \"\"\"\n    Compute adjustment factor based on residual ratio and iteration.\n    \"\"\"\n    # Diminishing influence over iterations\n    t = tau(k)\n    # Target ratio is 1, so if ratio > 1, rho should increase\n    # Use sqrt to make adjustments more moderate\n    # Clip the adjustment to prevent extreme changes\n    adj = np.sqrt(ratio)\n    # Bound the adjustment between 0.5 and 2.0\n    adj = np.clip(adj, 0.5, 2.0)\n    # Blend with base factor, with diminishing influence over iterations\n    factor = base + (adj - base) * np.exp(-k / 10.0)\n    return factor\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # If both residuals are very small, keep rho\n    if r_norm < eps and s_norm < eps:\n        return rho, 0.0, \"keep\"\n    \n    # Determine if we need to adjust rho\n    # Use a dynamic threshold that tightens over iterations\n    # Early iterations: be more aggressive (larger mu)\n    # Later iterations: be more conservative (smaller mu)\n    dynamic_mu = mu * (1.0 + 2.0 * np.exp(-k / 5.0))\n    \n    if ratio > dynamic_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to prioritize primal feasibility\n        factor = compute_adjustment_factor(ratio, k)\n        new_rho = rho * factor\n        return new_rho, factor, \"mul\"\n    elif 1.0 / ratio > dynamic_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to prioritize dual feasibility\n        factor = compute_adjustment_factor(1.0 / ratio, k)\n        new_rho = rho / factor\n        return new_rho, factor, \"div\"\n    else:\n        # Residuals are balanced\n        return rho, 1.0, \"keep\"\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, I notice it has a fitness score of 0.0766, which is lower than the top-performing programs (0.0829). The current approach uses a helper function `compute_adjustment_factor` which seems to be making adjustments based on the residual ratio, but it might be too complex and not aggressive enough in early iterations. Also, the dynamic threshold `dynamic_mu` is set to be larger in early iterations, which might be counterproductive because we want to be more sensitive to imbalances early on.\n\nThe top-performing programs are simpler and use a piecewise strategy for the update factor based on iteration count, with more aggressive updates early and more conservative updates later. They also use both `r_ratio` and `s_ratio` separately, which is more precise than just using `ratio` and `1/ratio`.\n\nLet's simplify the current approach by adopting a strategy similar to the top performers, but with some adjustments to potentially improve convergence. We'll:\n1. Remove the helper function to reduce complexity.\n2. Use both `r_ratio` and `s_ratio` for clarity.\n3. Use a piecewise base factor that is more aggressive early (like 1.5 for k<5, 1.2 for k<20, 1.1 otherwise).\n4. Incorporate a diminishing component via `tau` to reduce updates over time.\n5. Add bounds to prevent extreme changes.\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef compute_adjustment_factor(ratio, k, base=0.85):\n    \"\"\"\n    Compute adjustment factor based on residual ratio and iteration.\n    \"\"\"\n    # Diminishing influence over iterations\n    t = tau(k)\n    # Target ratio is 1, so if ratio > 1, rho should increase\n    # Use sqrt to make adjustments more moderate\n    # Clip the adjustment to prevent extreme changes\n    adj = np.sqrt(ratio)\n    # Bound the adjustment between 0.5 and 2.0\n    adj = np.clip(adj, 0.5, 2.0)\n    # Blend with base factor, with diminishing influence over iterations\n    factor = base + (adj - base) * np.exp(-k / 10.0)\n    return factor\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # If both residuals are very small, keep rho\n    if r_norm < eps and s_norm < eps:\n        return rho, 0.0, \"keep\"\n    \n    # Determine if we need to adjust rho\n    # Use a dynamic threshold that tightens over iterations\n    # Early iterations: be more aggressive (larger mu)\n    # Later iterations: be more conservative (smaller mu)\n    dynamic_mu = mu * (1.0 + 2.0 * np.exp(-k / 5.0))\n    \n    if ratio > dynamic_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to prioritize primal feasibility\n        factor = compute_adjustment_factor(ratio, k)\n        new_rho = rho * factor\n        return new_rho, factor, \"mul\"\n    elif 1.0 / ratio > dynamic_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to prioritize dual feasibility\n        factor = compute_adjustment_factor(1.0 / ratio, k)\n        new_rho = rho / factor\n        return new_rho, factor, \"div\"\n    else:\n        # Residuals are balanced\n        return rho, 1.0, \"keep\"\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute both ratios for balanced decision\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using both ratios\n    if r_ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the larger ratio as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThis change removes the helper function and replaces the update logic with a simpler, more effective strategy that has been shown to work well in the top-performing programs. The key improvements are:\n1. Using both `r_ratio` and `s_ratio` for more precise updates.\n2. A piecewise base factor that is more aggressive in early iterations (1.5 when k<5) and becomes more conservative over time.\n3. Incorporating a diminishing component via `tau` to reduce the update factor as iterations progress.\n4. Adding bounds to prevent extreme changes per iteration (max_change = 10.0) which helps with numerical stability.\n5. Using a fixed `mu` threshold (3.0) rather than a dynamic one that increases early, which might have been causing less sensitivity to imbalances when we actually want to be more sensitive.\n\nThis approach should lead to faster convergence by making appropriate updates to `rho` when residuals are imbalanced, especially in early iterations, while maintaining stability in later iterations."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}