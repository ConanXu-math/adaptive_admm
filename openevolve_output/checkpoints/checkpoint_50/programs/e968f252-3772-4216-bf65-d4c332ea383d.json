{"id": "e968f252-3772-4216-bf65-d4c332ea383d", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute both ratios for balanced decision\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using both ratios\n    if r_ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the larger ratio as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "b8a3011d-6b93-4d20-931d-54a24016d74c", "generation": 3, "timestamp": 1768219648.333001, "iteration_found": 46, "metrics": {"combined_score": 0.08292338142301477, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08292338142301477}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "0.017s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 76 lines with 72 lines", "parent_metrics": {"combined_score": 0.08261401069195577, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08261401069195577}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "0.008s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in numerical optimization and ADMM algorithms.\n\nYour task is to improve the function update_rho(rho, k, r_norm, s_norm, ...)\nused to adaptively update the ADMM penalty parameter.\n\nGoals:\n- Achieve faster convergence (fewer ADMM iterations)\n- Maintain numerical stability (avoid oscillating rho)\n- Balance primal and dual residuals efficiently\n\nConstraints:\n- You may ONLY modify the body of update_rho and helper functions in initial_program.py\n- The function signature and return types must remain unchanged\n- The code must be deterministic and numerically safe\n\nHints:\n- Consider using ratios or log-ratios of r_norm and s_norm\n- Early iterations may benefit from aggressive updates\n- Later iterations should favor stability\n- Piecewise or stateful strategies are allowed\n", "user": "# Current Program Information\n- Fitness: 0.0826\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0829 \u2192 0.0826. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 62 lines with 65 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.007s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 45 lines with 64 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.045s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 75 lines with 92 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292794781575066}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.016s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    # Also, if residuals are large, be more sensitive\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration and residual scale\n    if k < 5:\n        # Very early: very aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    # Use a smoother approach: compute a weighted decision\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # The factor should be between base_factor and 1.0, but we want >1\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292794781575066}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.016s'})\n\n### Program 2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Adjust factor with diminishing component\n    # We want to reduce the factor as iterations increase\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.045s'})\n\n### Program 3 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute both ratios for balanced decision\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using both ratios\n    if r_ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the larger ratio as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.007s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Use a fixed mu for simplicity (like the best performer)\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information (like the best performer)\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor with diminishing component\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using the standard mu threshold\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0829, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    # Also, if residuals are large, be more sensitive\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration and residual scale\n    if k < 5:\n        # Very early: very aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    # Use a smoother approach: compute a weighted decision\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # The factor should be between base_factor and 1.0, but we want >1\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0826, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early (smaller threshold)\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # The adjustment factor should be between base_factor and 1/base_factor\n    # But we want to make sure updates are not too small\n    if ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to penalize primal infeasibility more\n        # Use a factor that decreases with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to penalize dual infeasibility more\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], NumPy-based implementation, Comprehensive implementation\n\n### Inspiration 3 (Score: 0.0753, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Adjust mu based on iteration: more aggressive early, more stable later\n    # Early iterations: lower threshold to update more frequently\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Determine update factor based on the ratio and iteration\n    # Use a smoother function: sqrt(ratio) gives moderate adjustments\n    # Bound the adjustment between 1.1 and 2.0\n    t = tau(k, c, p)\n    \n    # Compute base factor that diminishes with iterations\n    # Start with 1.5 for early iterations, then 1.2, then 1.1\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Update logic\n    if ratio > effective_mu:\n        # Primal residual too large: increase rho\n        # Use sqrt(ratio) to make adjustment proportional to imbalance\n        raw_factor = np.sqrt(ratio)\n        # Blend with base_factor using t for smooth transition\n        factor = base_factor + (raw_factor - base_factor) * t\n        # Ensure factor is within reasonable bounds\n        factor = min(max(factor, 1.05), 2.0)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Dual residual too large: decrease rho\n        raw_factor = np.sqrt(1.0 / ratio)\n        factor = base_factor + (raw_factor - base_factor) * t\n        factor = min(max(factor, 1.05), 2.0)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Balanced residuals\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the log ratio as auxiliary information (more informative)\n    aux = np.log(ratio) if ratio > 0 else -np.inf\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early (smaller threshold)\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # The adjustment factor should be between base_factor and 1/base_factor\n    # But we want to make sure updates are not too small\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to penalize primal infeasibility more\n        # Use a factor that decreases with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to penalize dual infeasibility more\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, I notice it's performing well but there's room for improvement. The fitness score has slightly declined from 0.0829 to 0.0826. The current approach uses a fixed effective_mu that changes at iteration 10, and uses base_factor that changes at iterations 5 and 20. However, the top-performing programs have more sophisticated strategies.\n\nKey observations:\n1. The best performers (Program 1, 2, 3) all achieve 0.0829 with 12 iterations\n2. They use either a single ratio or both ratios, but with consistent strategies\n3. Some use additional safeguards like max_change to prevent large jumps\n4. The current program doesn't have max_change, which might lead to instability\n\nLet's improve by:\n1. Adding a max_change safeguard to prevent large jumps in rho\n2. Making the update factor more responsive to the degree of imbalance\n3. Using a smoother transition between early and late iterations\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early (smaller threshold)\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # The adjustment factor should be between base_factor and 1/base_factor\n    # But we want to make sure updates are not too small\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to penalize primal infeasibility more\n        # Use a factor that decreases with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to penalize dual infeasibility more\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute both ratios for balanced decision\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using both ratios\n    if r_ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the larger ratio as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThis change simplifies the approach by:\n1. Using a fixed mu (3.0) instead of varying effective_mu, which is consistent with top performers\n2. Adding max_change safeguard to prevent large jumps in rho, which improves stability\n3. Using max(r_ratio, s_ratio) for aux, which is more informative\n4. Removing the effective_mu adjustment which might have been causing issues\n\nThis approach is similar to Program 3 which scored 0.0829, but with the addition of max_change for better stability. The max_change prevents rho from changing too dramatically in a single iteration, which can help convergence.\n\nThe factor calculation remains the same, which has been shown to work well. By keeping the base_factor schedule and tau adjustment, we maintain a good balance between early aggressiveness and later stability.\n\nThis should help improve the fitness score back to 0.0829 or better by providing more stable updates while maintaining the ability to adjust rho appropriately."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}