{"id": "5dd531bc-3afc-4310-bef5-a5efc0dce79f", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration\n    if k < 5:\n        # Very early: aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "f235c50a-0e2d-4a27-9640-7931bbbfbbf2", "generation": 3, "timestamp": 1768219710.559062, "iteration_found": 50, "metrics": {"combined_score": 0.08292794781575066, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08292794781575066}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "0.016s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 75 lines with 89 lines", "parent_metrics": {"combined_score": 0.08261401069195577, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08261401069195577}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "0.024s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in numerical optimization and ADMM algorithms.\n\nYour task is to improve the function update_rho(rho, k, r_norm, s_norm, ...)\nused to adaptively update the ADMM penalty parameter.\n\nGoals:\n- Achieve faster convergence (fewer ADMM iterations)\n- Maintain numerical stability (avoid oscillating rho)\n- Balance primal and dual residuals efficiently\n\nConstraints:\n- You may ONLY modify the body of update_rho and helper functions in initial_program.py\n- The function signature and return types must remain unchanged\n- The code must be deterministic and numerically safe\n\nHints:\n- Consider using ratios or log-ratios of r_norm and s_norm\n- Early iterations may benefit from aggressive updates\n- Later iterations should favor stability\n- Piecewise or stateful strategies are allowed\n", "user": "# Current Program Information\n- Fitness: 0.0826\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0829 \u2192 0.0826. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 71 lines with 64 lines\nChange 2: Replace 15 lines with \n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.012s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 45 lines with 64 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.045s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 75 lines with 92 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292794781575066}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.016s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    # Also, if residuals are large, be more sensitive\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration and residual scale\n    if k < 5:\n        # Very early: very aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    # Use a smoother approach: compute a weighted decision\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # The factor should be between base_factor and 1.0, but we want >1\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292794781575066}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.016s'})\n\n### Program 2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Adjust factor with diminishing component\n    # We want to reduce the factor as iterations increase\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.045s'})\n\n### Program 3 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.012s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base factor based on iteration count\n    # Early iterations: more aggressive updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to make updates diminish over time\n    t = tau(k, c, p)\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using the ratio and its reciprocal\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute both ratios for balanced decision\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using both ratios\n    if r_ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the larger ratio as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0829, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    # Also, if residuals are large, be more sensitive\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration and residual scale\n    if k < 5:\n        # Very early: very aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    # Use a smoother approach: compute a weighted decision\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # The factor should be between base_factor and 1.0, but we want >1\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0766, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef compute_adjustment_factor(ratio, k, base=0.85):\n    \"\"\"\n    Compute adjustment factor based on residual ratio and iteration.\n    \"\"\"\n    # Diminishing influence over iterations\n    t = tau(k)\n    # Target ratio is 1, so if ratio > 1, rho should increase\n    # Use sqrt to make adjustments more moderate\n    # Clip the adjustment to prevent extreme changes\n    adj = np.sqrt(ratio)\n    # Bound the adjustment between 0.5 and 2.0\n    adj = np.clip(adj, 0.5, 2.0)\n    # Blend with base factor, with diminishing influence over iterations\n    factor = base + (adj - base) * np.exp(-k / 10.0)\n    return factor\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # If both residuals are very small, keep rho\n    if r_norm < eps and s_norm < eps:\n        return rho, 0.0, \"keep\"\n    \n    # Determine if we need to adjust rho\n    # Use a dynamic threshold that tightens over iterations\n    # Early iterations: be more aggressive (larger mu)\n    # Later iterations: be more conservative (smaller mu)\n    dynamic_mu = mu * (1.0 + 2.0 * np.exp(-k / 5.0))\n    \n    if ratio > dynamic_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to prioritize primal feasibility\n        factor = compute_adjustment_factor(ratio, k)\n        new_rho = rho * factor\n        return new_rho, factor, \"mul\"\n    elif 1.0 / ratio > dynamic_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to prioritize dual feasibility\n        factor = compute_adjustment_factor(1.0 / ratio, k)\n        new_rho = rho / factor\n        return new_rho, factor, \"div\"\n    else:\n        # Residuals are balanced\n        return rho, 1.0, \"keep\"\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 3 (Score: 0.0762, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of primal to dual residual\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration and ratio\n    # Early iterations: more aggressive updates\n    if k < 5:\n        # Very aggressive in the first few iterations\n        base_factor = 1.8\n    elif k < 15:\n        # Moderate updates\n        base_factor = 1.4\n    else:\n        # Conservative updates for stability\n        base_factor = 1.1\n    \n    # Use tau to make updates diminish over time\n    t = tau(k, c, p)\n    # The factor should decrease as iterations increase\n    factor = base_factor - 0.5 * t\n    # Ensure factor is at least 1.05\n    factor = max(factor, 1.05)\n    \n    # Check if we need to update\n    # Use a dynamic mu that becomes stricter over time\n    # Early iterations: allow more imbalance to explore\n    if k < 10:\n        effective_mu = 4.0\n    else:\n        effective_mu = mu\n    \n    if ratio > effective_mu:\n        # Primal residual is too large: increase rho\n        # Make the update proportional to the square root of the ratio, but bounded\n        # This helps to adjust more when the imbalance is larger\n        adjustment = min(np.sqrt(ratio), factor)\n        new_rho = rho * adjustment\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Dual residual is too large: decrease rho\n        adjustment = min(np.sqrt(1.0 / ratio), factor)\n        new_rho = rho / adjustment\n        mode = \"div\"\n    else:\n        # Balanced residuals\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to maintain numerical stability\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    # Use log ratio as auxiliary information for better scaling\n    aux = np.log(ratio + 1e-16)\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration to be more aggressive early on\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine update factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # The adjustment factor should be between base_factor and 1/base_factor\n    # But we want to make sure updates are not too small\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to penalize primal infeasibility more\n        # Use a factor that decreases with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to penalize dual infeasibility more\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, I notice it's similar to some of the top-performing programs but with slight differences. The fitness score has declined slightly (0.0829 to 0.0826), so we need to improve it. The top programs achieve a score of 0.0829 with 12 iterations, which is better.\n\nKey observations:\n1. The current program uses a fixed effective_mu that changes at k=10, but top programs use more dynamic thresholds.\n2. The update factor is computed as base_factor - t, which can be too aggressive or not aggressive enough.\n3. The top programs use a more sophisticated approach with residual scaling and logarithmic adjustments.\n\nLet's aim to make the update strategy more balanced and adaptive, similar to the best-performing program (Program 1), but simpler to avoid code length issues (the note says code length exceeds 500 characters, but that's not a strict constraint? The note says \"Consider simplifying - code length exceeds 500 characters\", but the top program is longer. However, we should aim for a balance).\n\nI'll make the following changes:\n1. Use a dynamic effective_mu that adjusts based on iteration and residual scale.\n2. Use a smoother update factor that depends on the excess ratio.\n3. Add bounds to prevent large jumps.\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration to be more aggressive early on\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine update factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # The adjustment factor should be between base_factor and 1/base_factor\n    # But we want to make sure updates are not too small\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to penalize primal infeasibility more\n        # Use a factor that decreases with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to penalize dual infeasibility more\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration\n    if k < 5:\n        # Very early: aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThis change makes the update strategy more adaptive by:\n1. Using residual_scale to adjust the threshold based on the magnitude of residuals.\n2. Using a logarithmic scaling for the update factor, which makes updates more moderate when the imbalance is not too large.\n3. Adding a max_change per iteration to prevent oscillations.\n4. Using a more nuanced effective_mu that changes with iteration and residual scale.\n\nThis approach is similar to the top-performing program (Program 1) which achieved a score of 0.0829. By incorporating these elements, we aim to improve convergence and stability, which should lead to fewer iterations and better fitness."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}