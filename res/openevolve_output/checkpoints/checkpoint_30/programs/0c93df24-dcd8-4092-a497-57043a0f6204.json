{"id": "0c93df24-dcd8-4092-a497-57043a0f6204", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, avoiding division by zero\n    ratio = (r_norm + eps) / (s_norm + eps)\n    \n    # Target ratio is 1, so we want ratio to be close to 1\n    # If ratio > mu, primal residual is too large -> increase rho\n    # If ratio < 1/mu, dual residual is too large -> decrease rho\n    # Use a smoother update factor based on sqrt(ratio) dampened by t\n    # Cap the maximum adjustment to avoid extreme changes\n    if ratio > mu:\n        # Increase rho by factor proportional to sqrt(ratio)\n        # But dampen with t to avoid large jumps in later iterations\n        adj = np.sqrt(ratio)\n        # Bound adjustment between 1.0 and 2.0\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho * fac, t, \"mul\"\n    elif ratio < 1.0 / mu:\n        # Decrease rho\n        adj = np.sqrt(1.0 / ratio)\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho / fac, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n", "language": "python", "parent_id": "259f4c0a-a60e-4579-a5c4-2fd277a65a3c", "generation": 2, "timestamp": 1768219198.7754738, "iteration_found": 12, "metrics": {"combined_score": 0.0766992980527246, "metrics": {"converged": true, "iters": 13, "combined_score": 0.0766992980527246}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "0.019s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 56 lines with 51 lines", "parent_metrics": {"combined_score": 0.06870474147754688, "metrics": {"converged": true, "iters": 14, "combined_score": 0.06870474147754688}, "artifacts": {"status": "CONVERGED", "iterations": 14, "eval_time": "0.034s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in numerical optimization and ADMM algorithms.\n\nYour task is to improve the function update_rho(rho, k, r_norm, s_norm, ...)\nused to adaptively update the ADMM penalty parameter.\n\nGoals:\n- Achieve faster convergence (fewer ADMM iterations)\n- Maintain numerical stability (avoid oscillating rho)\n- Balance primal and dual residuals efficiently\n\nConstraints:\n- You may ONLY modify the body of update_rho and helper functions in initial_program.py\n- The function signature and return types must remain unchanged\n- The code must be deterministic and numerically safe\n\nHints:\n- Consider using ratios or log-ratios of r_norm and s_norm\n- Early iterations may benefit from aggressive updates\n- Later iterations should favor stability\n- Piecewise or stateful strategies are allowed\n", "user": "# Current Program Information\n- Fitness: 0.0687\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0712 \u2192 0.0687. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 37 lines with 45 lines\n- Metrics: combined_score: 0.0712, metrics: {'converged': True, 'iters': 14, 'combined_score': 0.0711810220834738}, artifacts: {'status': 'CONVERGED', 'iterations': 14, 'eval_time': '0.008s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 10 lines with 40 lines\n- Metrics: combined_score: 0.0753, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07533695935828097}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '0.006s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 10 lines with 19 lines\nChange 2: Replace 19 lines with 25 lines\n- Metrics: combined_score: 0.0767, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.0766992980527246}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '0.007s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0767)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, avoiding division by zero\n    ratio = (r_norm + eps) / (s_norm + eps)\n    \n    # Target ratio is 1, so we want ratio to be close to 1\n    # If ratio > mu, primal residual is too large -> increase rho\n    # If ratio < 1/mu, dual residual is too large -> decrease rho\n    # Use a smoother update factor based on sqrt(ratio) dampened by t\n    # Cap the maximum adjustment to avoid extreme changes\n    if ratio > mu:\n        # Increase rho by factor proportional to sqrt(ratio)\n        # But dampen with t to avoid large jumps in later iterations\n        adj = np.sqrt(ratio)\n        # Bound adjustment between 1.0 and 2.0\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho * fac, t, \"mul\"\n    elif ratio < 1.0 / mu:\n        # Decrease rho\n        adj = np.sqrt(1.0 / ratio)\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho / fac, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n\n```\nKey features: Performs well on combined_score (0.0767), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.0766992980527246}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '0.007s'})\n\n### Program 2 (Score: 0.0753)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Early iterations: more aggressive, later: more conservative\n    # Use a dynamic threshold that tightens over time\n    # mu is scaled by (1 + t) to be more permissive early, stricter later\n    dynamic_mu = mu * (1.0 + 2.0 * t)  # Starts larger, decreases to mu\n    \n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # If ratio is too large, increase rho; if too small, decrease rho\n    # But we want to avoid oscillating, so update smoothly\n    # Target ratio is 1.0\n    if ratio > dynamic_mu:\n        # Increase rho to reduce primal residual\n        # Update factor based on sqrt(ratio) but bounded\n        fac = np.sqrt(ratio)\n        # Clip factor to prevent extreme updates\n        fac = min(fac, 1.5)\n        # Make updates more aggressive early on\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho * fac\n        mode = \"mul\"\n    elif 1.0 / ratio > dynamic_mu:\n        # Decrease rho to reduce dual residual\n        fac = np.sqrt(1.0 / ratio)\n        fac = min(fac, 1.5)\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho / fac\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Ensure rho doesn't become too large or too small\n    # Clip to a reasonable range\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    return new_rho, t, mode\n\n```\nKey features: Performs well on combined_score (0.0753), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07533695935828097}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '0.006s'})\n\n### Program 3 (Score: 0.0712)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Adjust mu to be tighter as iterations increase\n    # Start with a larger threshold early, then reduce to enforce balance\n    mu_adj = mu * (1.0 + 2.0 * np.exp(-0.1 * k))\n    \n    # Dynamic factor: more aggressive early, conservative later\n    # Base factor between 1.1 and 1.5 when k=0, decreasing to around 1.05\n    base_factor = 1.5 - 0.4 * np.tanh(0.1 * k)\n    fac = base_factor + t\n    \n    # Check if residuals are imbalanced\n    if r_norm > mu_adj * max(s_norm, eps):\n        return rho * fac, t, \"mul\"\n    \n    if s_norm > mu_adj * max(r_norm, eps):\n        return rho / fac, t, \"div\"\n    \n    return rho, t, \"keep\"\n\n```\nKey features: Performs well on combined_score (0.0712), Performs well on metrics ({'converged': True, 'iters': 14, 'combined_score': 0.0711810220834738}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 14, 'eval_time': '0.008s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0687)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu to be more aggressive early and more stable later\n    # Start with mu=3.0 and approach 2.0 as k increases\n    dynamic_mu = 3.0 - 1.0 * min(k / 50.0, 1.0)\n    \n    # Compute ratio with safeguards\n    ratio = r_norm / max(s_norm, eps)\n    log_ratio = np.log(ratio) if ratio > 0 else 0.0\n    \n    # Determine update factor based on the ratio and iteration\n    t = tau(k, c, p)\n    # Base factor: more aggressive updates when residuals are imbalanced\n    # Use a sigmoid-like function to bound the factor between 1.1 and 1.5 early, and 1.05 and 1.2 later\n    base_aggression = 1.5 - 0.4 * min(k / 100.0, 1.0)\n    # Adjust factor based on log ratio magnitude\n    if abs(log_ratio) > 0.1:\n        # When ratio is far from 1, be more aggressive\n        factor = base_aggression + 0.1 * min(abs(log_ratio), 2.0)\n    else:\n        factor = 1.05 + t\n    \n    # Ensure factor is within reasonable bounds\n    factor = min(max(factor, 1.01), 2.0)\n    \n    # Update decision\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        return rho * factor, t, \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        return rho / factor, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0430)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    fac = 0.85 + t\n\n    if r_norm > mu * max(s_norm, eps):\n        return rho * fac, t, \"mul\"\n\n    if s_norm > mu * max(r_norm, eps):\n        return rho / fac, t, \"div\"\n\n    return rho, t, \"keep\"\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0767, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, avoiding division by zero\n    ratio = (r_norm + eps) / (s_norm + eps)\n    \n    # Target ratio is 1, so we want ratio to be close to 1\n    # If ratio > mu, primal residual is too large -> increase rho\n    # If ratio < 1/mu, dual residual is too large -> decrease rho\n    # Use a smoother update factor based on sqrt(ratio) dampened by t\n    # Cap the maximum adjustment to avoid extreme changes\n    if ratio > mu:\n        # Increase rho by factor proportional to sqrt(ratio)\n        # But dampen with t to avoid large jumps in later iterations\n        adj = np.sqrt(ratio)\n        # Bound adjustment between 1.0 and 2.0\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho * fac, t, \"mul\"\n    elif ratio < 1.0 / mu:\n        # Decrease rho\n        adj = np.sqrt(1.0 / ratio)\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho / fac, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0753, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Early iterations: more aggressive, later: more conservative\n    # Use a dynamic threshold that tightens over time\n    # mu is scaled by (1 + t) to be more permissive early, stricter later\n    dynamic_mu = mu * (1.0 + 2.0 * t)  # Starts larger, decreases to mu\n    \n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # If ratio is too large, increase rho; if too small, decrease rho\n    # But we want to avoid oscillating, so update smoothly\n    # Target ratio is 1.0\n    if ratio > dynamic_mu:\n        # Increase rho to reduce primal residual\n        # Update factor based on sqrt(ratio) but bounded\n        fac = np.sqrt(ratio)\n        # Clip factor to prevent extreme updates\n        fac = min(fac, 1.5)\n        # Make updates more aggressive early on\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho * fac\n        mode = \"mul\"\n    elif 1.0 / ratio > dynamic_mu:\n        # Decrease rho to reduce dual residual\n        fac = np.sqrt(1.0 / ratio)\n        fac = min(fac, 1.5)\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho / fac\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Ensure rho doesn't become too large or too small\n    # Clip to a reasonable range\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    return new_rho, t, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 3 (Score: 0.0430, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    fac = 0.85 + t\n\n    if r_norm > mu * max(s_norm, eps):\n        return rho * fac, t, \"mul\"\n\n    if s_norm > mu * max(r_norm, eps):\n        return rho / fac, t, \"div\"\n\n    return rho, t, \"keep\"\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], NumPy-based implementation, Comprehensive implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu to be more aggressive early and more stable later\n    # Start with mu=3.0 and approach 2.0 as k increases\n    dynamic_mu = 3.0 - 1.0 * min(k / 50.0, 1.0)\n    \n    # Compute ratio with safeguards\n    ratio = r_norm / max(s_norm, eps)\n    log_ratio = np.log(ratio) if ratio > 0 else 0.0\n    \n    # Determine update factor based on the ratio and iteration\n    t = tau(k, c, p)\n    # Base factor: more aggressive updates when residuals are imbalanced\n    # Use a sigmoid-like function to bound the factor between 1.1 and 1.5 early, and 1.05 and 1.2 later\n    base_aggression = 1.5 - 0.4 * min(k / 100.0, 1.0)\n    # Adjust factor based on log ratio magnitude\n    if abs(log_ratio) > 0.1:\n        # When ratio is far from 1, be more aggressive\n        factor = base_aggression + 0.1 * min(abs(log_ratio), 2.0)\n    else:\n        factor = 1.05 + t\n    \n    # Ensure factor is within reasonable bounds\n    factor = min(max(factor, 1.01), 2.0)\n    \n    # Update decision\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        return rho * factor, t, \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        return rho / factor, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the evolution history, the best performing program (Score: 0.0767) is simpler and uses a different strategy than the current program (Score: 0.0687). The current program has become more complex with dynamic thresholds and log ratios, which may be causing instability or slower convergence.\n\nThe top program uses:\n1. A fixed mu threshold (3.0)\n2. Updates based on sqrt(ratio) with diminishing step size t\n3. Bounded adjustments between 1.0 and 2.0\n4. Smooth updates via `fac = 1.0 + t * (adj - 1.0)`\n\nThis approach seems more stable and effective. The current program's dynamic_mu and log-based factor calculation might be overcomplicating things, leading to less optimal updates.\n\nLet's simplify and adopt the best strategy while making sure to:\n1. Keep the signature unchanged\n2. Use the same tau function\n3. Maintain numerical stability\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu to be more aggressive early and more stable later\n    # Start with mu=3.0 and approach 2.0 as k increases\n    dynamic_mu = 3.0 - 1.0 * min(k / 50.0, 1.0)\n    \n    # Compute ratio with safeguards\n    ratio = r_norm / max(s_norm, eps)\n    log_ratio = np.log(ratio) if ratio > 0 else 0.0\n    \n    # Determine update factor based on the ratio and iteration\n    t = tau(k, c, p)\n    # Base factor: more aggressive updates when residuals are imbalanced\n    # Use a sigmoid-like function to bound the factor between 1.1 and 1.5 early, and 1.05 and 1.2 later\n    base_aggression = 1.5 - 0.4 * min(k / 100.0, 1.0)\n    # Adjust factor based on log ratio magnitude\n    if abs(log_ratio) > 0.1:\n        # When ratio is far from 1, be more aggressive\n        factor = base_aggression + 0.1 * min(abs(log_ratio), 2.0)\n    else:\n        factor = 1.05 + t\n    \n    # Ensure factor is within reasonable bounds\n    factor = min(max(factor, 1.01), 2.0)\n    \n    # Update decision\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        return rho * factor, t, \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        return rho / factor, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, avoiding division by zero\n    ratio = (r_norm + eps) / (s_norm + eps)\n    \n    # Target ratio is 1, so we want ratio to be close to 1\n    # If ratio > mu, primal residual is too large -> increase rho\n    # If ratio < 1/mu, dual residual is too large -> decrease rho\n    # Use a smoother update factor based on sqrt(ratio) dampened by t\n    # Cap the maximum adjustment to avoid extreme changes\n    if ratio > mu:\n        # Increase rho by factor proportional to sqrt(ratio)\n        # But dampen with t to avoid large jumps in later iterations\n        adj = np.sqrt(ratio)\n        # Bound adjustment between 1.0 and 2.0\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho * fac, t, \"mul\"\n    elif ratio < 1.0 / mu:\n        # Decrease rho\n        adj = np.sqrt(1.0 / ratio)\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho / fac, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n>>>>>>> REPLACE\n\nThis change replaces the complex dynamic threshold and log-based factor calculation with a simpler, more effective approach from the top-performing program. The key improvements are:\n\n1. **Fixed mu threshold**: Uses a constant mu=3.0 instead of dynamic_mu which changes with iteration. This provides consistent balancing criteria.\n2. **Smooth updates**: The update factor is based on sqrt(ratio) and scaled by the diminishing step size t, which makes updates aggressive when needed but conservative in later iterations.\n3. **Bounded adjustments**: The adjustment is capped at 2.0 to prevent extreme changes.\n4. **Numerical stability**: Uses eps in both numerator and denominator to avoid division by zero.\n\nThis should lead to faster convergence (fewer iterations) and better numerical stability, improving the fitness score. The approach has been proven to work well in the top program (score 0.0767 vs current 0.0687)."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}