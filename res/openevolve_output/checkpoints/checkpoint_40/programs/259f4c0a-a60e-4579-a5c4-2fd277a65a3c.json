{"id": "259f4c0a-a60e-4579-a5c4-2fd277a65a3c", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu to be more aggressive early and more stable later\n    # Start with mu=3.0 and approach 2.0 as k increases\n    dynamic_mu = 3.0 - 1.0 * min(k / 50.0, 1.0)\n    \n    # Compute ratio with safeguards\n    ratio = r_norm / max(s_norm, eps)\n    log_ratio = np.log(ratio) if ratio > 0 else 0.0\n    \n    # Determine update factor based on the ratio and iteration\n    t = tau(k, c, p)\n    # Base factor: more aggressive updates when residuals are imbalanced\n    # Use a sigmoid-like function to bound the factor between 1.1 and 1.5 early, and 1.05 and 1.2 later\n    base_aggression = 1.5 - 0.4 * min(k / 100.0, 1.0)\n    # Adjust factor based on log ratio magnitude\n    if abs(log_ratio) > 0.1:\n        # When ratio is far from 1, be more aggressive\n        factor = base_aggression + 0.1 * min(abs(log_ratio), 2.0)\n    else:\n        factor = 1.05 + t\n    \n    # Ensure factor is within reasonable bounds\n    factor = min(max(factor, 1.01), 2.0)\n    \n    # Update decision\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        return rho * factor, t, \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        return rho / factor, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n", "language": "python", "parent_id": "e3e7b7e1-1592-4d78-8c9c-6a76f7a88c15", "generation": 1, "timestamp": 1768219089.100397, "iteration_found": 3, "metrics": {"combined_score": 0.06870474147754688, "metrics": {"converged": true, "iters": 14, "combined_score": 0.06870474147754688}, "artifacts": {"status": "CONVERGED", "iterations": 14, "eval_time": "0.034s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 37 lines with 56 lines", "parent_metrics": {"combined_score": 0.043007227611818806, "metrics": {"converged": true, "iters": 23, "combined_score": 0.043007227611818806}, "artifacts": {"status": "CONVERGED", "iterations": 23, "eval_time": "0.021s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in numerical optimization and ADMM algorithms.\n\nYour task is to improve the function update_rho(rho, k, r_norm, s_norm, ...)\nused to adaptively update the ADMM penalty parameter.\n\nGoals:\n- Achieve faster convergence (fewer ADMM iterations)\n- Maintain numerical stability (avoid oscillating rho)\n- Balance primal and dual residuals efficiently\n\nConstraints:\n- You may ONLY modify the body of update_rho and helper functions in initial_program.py\n- The function signature and return types must remain unchanged\n- The code must be deterministic and numerically safe\n\nHints:\n- Consider using ratios or log-ratios of r_norm and s_norm\n- Early iterations may benefit from aggressive updates\n- Later iterations should favor stability\n- Piecewise or stateful strategies are allowed\n", "user": "# Current Program Information\n- Fitness: 0.0430\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.0430\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: combined_score: 0.0430, metrics: {'converged': True, 'iters': 23, 'combined_score': 0.043007227611818806}, artifacts: {'status': 'CONVERGED', 'iterations': 23, 'eval_time': '0.021s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0430)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    fac = 0.85 + t\n\n    if r_norm > mu * max(s_norm, eps):\n        return rho * fac, t, \"mul\"\n\n    if s_norm > mu * max(r_norm, eps):\n        return rho / fac, t, \"div\"\n\n    return rho, t, \"keep\"\n\n```\nKey features: Performs well on combined_score (0.0430), Performs well on metrics ({'converged': True, 'iters': 23, 'combined_score': 0.043007227611818806}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 23, 'eval_time': '0.021s'})\n\n\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    fac = 0.85 + t\n\n    if r_norm > mu * max(s_norm, eps):\n        return rho * fac, t, \"mul\"\n\n    if s_norm > mu * max(r_norm, eps):\n        return rho / fac, t, \"div\"\n\n    return rho, t, \"keep\"\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current implementation, the update strategy uses a fixed `mu=3.0` and a factor `fac = 0.85 + tau(k)`. The diminishing `tau` makes updates less aggressive over time, which is good for stability. However, we can improve by:\n\n1. Making the update more responsive to the ratio between primal and dual residuals\n2. Adjusting `mu` based on iteration count to be more aggressive early and more stable later\n3. Using a more balanced update factor\n\nLet's modify the update strategy to:\n- Use a dynamic `mu` that decreases with iterations to be less strict later\n- Adjust the update factor to be more balanced\n- Use a log-ratio to smooth updates\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    fac = 0.85 + t\n\n    if r_norm > mu * max(s_norm, eps):\n        return rho * fac, t, \"mul\"\n\n    if s_norm > mu * max(r_norm, eps):\n        return rho / fac, t, \"div\"\n\n    return rho, t, \"keep\"\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu to be more aggressive early and more stable later\n    # Start with mu=3.0 and approach 2.0 as k increases\n    dynamic_mu = 3.0 - 1.0 * min(k / 50.0, 1.0)\n    \n    # Compute ratio with safeguards\n    ratio = r_norm / max(s_norm, eps)\n    log_ratio = np.log(ratio) if ratio > 0 else 0.0\n    \n    # Determine update factor based on the ratio and iteration\n    t = tau(k, c, p)\n    # Base factor: more aggressive updates when residuals are imbalanced\n    # Use a sigmoid-like function to bound the factor between 1.1 and 1.5 early, and 1.05 and 1.2 later\n    base_aggression = 1.5 - 0.4 * min(k / 100.0, 1.0)\n    # Adjust factor based on log ratio magnitude\n    if abs(log_ratio) > 0.1:\n        # When ratio is far from 1, be more aggressive\n        factor = base_aggression + 0.1 * min(abs(log_ratio), 2.0)\n    else:\n        factor = 1.05 + t\n    \n    # Ensure factor is within reasonable bounds\n    factor = min(max(factor, 1.01), 2.0)\n    \n    # Update decision\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        return rho * factor, t, \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        return rho / factor, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n>>>>>>> REPLACE\n\nThis approach:\n1. Uses a dynamic `mu` that decreases from 3.0 to 2.0 over the first 50 iterations, allowing for more frequent updates early on\n2. Considers the actual ratio between primal and dual residuals via `log_ratio` to adjust the update factor\n3. Makes the update factor more aggressive when residuals are imbalanced, but bounds it to prevent instability\n4. Gradually reduces the aggressiveness of updates as iterations progress for better stability\n\nThis should lead to faster convergence by being more responsive to residual imbalances while maintaining numerical stability in later iterations."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}