{"id": "ca11551c-81ba-4221-aa02-b5c0e9af7056", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute both ratios\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    t = tau(k, c, p)\n    # Update logic\n    if r_ratio > effective_mu:\n        factor = max(base_factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        factor = max(base_factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Bound rho for numerical stability\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Auxiliary value\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "39761723-1885-406e-9302-ec27f21ef134", "generation": 2, "timestamp": 1768219356.329391, "iteration_found": 25, "metrics": {"combined_score": 0.08261401069195577, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08261401069195577}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "0.007s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 52 lines with 64 lines", "parent_metrics": {"combined_score": 0.0766992980527246, "metrics": {"converged": true, "iters": 13, "combined_score": 0.0766992980527246}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "0.007s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in numerical optimization and ADMM algorithms.\n\nYour task is to improve the function update_rho(rho, k, r_norm, s_norm, ...)\nused to adaptively update the ADMM penalty parameter.\n\nGoals:\n- Achieve faster convergence (fewer ADMM iterations)\n- Maintain numerical stability (avoid oscillating rho)\n- Balance primal and dual residuals efficiently\n\nConstraints:\n- You may ONLY modify the body of update_rho and helper functions in initial_program.py\n- The function signature and return types must remain unchanged\n- The code must be deterministic and numerically safe\n\nHints:\n- Consider using ratios or log-ratios of r_norm and s_norm\n- Early iterations may benefit from aggressive updates\n- Later iterations should favor stability\n- Piecewise or stateful strategies are allowed\n", "user": "# Current Program Information\n- Fitness: 0.0767\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0826 \u2192 0.0767. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 37 lines with 77 lines\n- Metrics: combined_score: 0.0826, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08261401069195577}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.008s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 62 lines with 75 lines\n- Metrics: combined_score: 0.0826, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08261401069195577}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.017s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 56 lines with 76 lines\n- Metrics: combined_score: 0.0826, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08261401069195577}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.008s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0826)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early (smaller threshold)\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # The adjustment factor should be between base_factor and 1/base_factor\n    # But we want to make sure updates are not too small\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to penalize primal infeasibility more\n        # Use a factor that decreases with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to penalize dual infeasibility more\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0826), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08261401069195577}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.008s'})\n\n### Program 2 (Score: 0.0826)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early, conservative later\n    if k < 10:\n        effective_mu = 2.0  # Lower threshold to update more frequently early\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base update factor based on iteration\n    # Early: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Check if we need to update\n    if ratio > effective_mu:\n        # Primal residual too large: increase rho\n        # Make factor diminish with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05 for meaningful updates\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Dual residual too large: decrease rho\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Balanced residuals\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to maintain numerical stability\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0826), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08261401069195577}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.017s'})\n\n### Program 3 (Score: 0.0826)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration to be more aggressive early on\n    # For early iterations, use a smaller threshold to update more frequently\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # The adjustment factor should be between base_factor and 1/base_factor\n    # But we want to make sure updates are not too small\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to penalize primal infeasibility more\n        # Use a factor that decreases with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to penalize dual infeasibility more\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0826), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08261401069195577}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.008s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0826)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early (update more frequently)\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute ratios\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration: larger updates early, smaller later\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Update logic\n    if r_ratio > effective_mu:\n        # Primal residual too large: increase rho\n        factor = max(base_factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual too large: decrease rho\n        factor = max(base_factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Balanced residuals\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Numerical stability: bound rho\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Auxiliary value: use the larger ratio\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0767)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Compute ratio with safeguards\n    ratio = (r_norm + eps) / (s_norm + eps)\n    \n    # If ratio is too large, increase rho; if too small, decrease rho\n    # Use sqrt(ratio) for smooth adjustment, bounded and dampened by t\n    if ratio > mu:\n        # Increase rho\n        adj = np.sqrt(ratio)\n        adj = min(adj, 2.0)  # Bound adjustment\n        fac = 1.0 + t * (adj - 1.0)\n        new_rho = rho * fac\n        mode = \"mul\"\n    elif ratio < 1.0 / mu:\n        # Decrease rho\n        adj = np.sqrt(1.0 / ratio)\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        new_rho = rho / fac\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to a reasonable range for numerical stability\n    rho_min = 1e-6\n    rho_max = 1e6\n    if new_rho > rho_max:\n        new_rho = rho_max\n        mode = \"clip\"\n    elif new_rho < rho_min:\n        new_rho = rho_min\n        mode = \"clip\"\n    \n    return new_rho, t, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0761, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Adjust mu based on iteration: start more permissive, become stricter\n    # For early iterations (k < 10), use a larger threshold to allow exploration\n    if k < 10:\n        dynamic_mu = mu * 2.0\n    else:\n        # Gradually tighten to mu by iteration 50\n        dynamic_mu = mu * (1.0 + np.exp(-0.1 * (k - 10)))\n    \n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration and ratio\n    # Early iterations: more aggressive (up to 2.0), later: more conservative (up to 1.3)\n    if k < 10:\n        base_factor = 1.8\n    elif k < 30:\n        base_factor = 1.5\n    else:\n        base_factor = 1.2\n    \n    # Adjust factor based on how far ratio is from 1, but bounded\n    # Use a smooth function: factor = base_factor + 0.1 * min(|log(ratio)|, 3.0)\n    # This makes updates larger when residuals are more imbalanced\n    if ratio > 0:\n        log_ratio = np.log(ratio)\n        adjustment = 0.1 * min(abs(log_ratio), 3.0)\n    else:\n        adjustment = 0.0\n    factor = base_factor + adjustment\n    \n    # Clip factor to reasonable bounds\n    factor = min(max(factor, 1.05), 2.5)\n    \n    # Update decision\n    if ratio > dynamic_mu:\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > dynamic_mu:\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Ensure rho stays within bounds\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    return new_rho, t, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0764, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Early iterations: more aggressive, later: more conservative\n    # Use a dynamic threshold that tightens over time\n    # mu is scaled by (1 + t) to be more permissive early, stricter later\n    # Make threshold more balanced: early iterations have higher threshold to allow exploration\n    # Later iterations have threshold closer to mu for precise balance\n    dynamic_mu = mu * (1.0 + 3.0 * t)  # More aggressive early permissiveness\n    \n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: more aggressive updates (larger factor)\n    # Later iterations: smaller updates for stability\n    # Use t to control aggressiveness: t is large early, small later\n    # We want update factor to be between 1.2 and 2.0 early, and 1.05 and 1.2 later\n    base_factor = 1.2 + 0.8 * t  # Early: up to 2.0, later: approaches 1.2\n    \n    if ratio > dynamic_mu:\n        # Increase rho to reduce primal residual\n        # Use a factor that's proportional to the square root of the ratio, but bounded\n        # Make it more aggressive early on\n        raw_factor = np.sqrt(ratio)\n        # Scale by base_factor, but ensure it's not too extreme\n        fac = min(raw_factor, base_factor)\n        # Ensure minimum update\n        fac = max(fac, 1.05)\n        new_rho = rho * fac\n        mode = \"mul\"\n    elif 1.0 / ratio > dynamic_mu:\n        # Decrease rho to reduce dual residual\n        raw_factor = np.sqrt(1.0 / ratio)\n        fac = min(raw_factor, base_factor)\n        fac = max(fac, 1.05)\n        new_rho = rho / fac\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Ensure rho doesn't become too large or too small\n    # Clip to a reasonable range\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    return new_rho, t, mode\n\n```\nUnique approach: [Fragment formatting error: 'metric_name'], NumPy-based implementation, Comprehensive implementation\n\n### Inspiration 3 (Score: 0.0687, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu to be more aggressive early and more stable later\n    # Start with mu=3.0 and approach 2.0 as k increases\n    dynamic_mu = 3.0 - 1.0 * min(k / 50.0, 1.0)\n    \n    # Compute ratio with safeguards\n    ratio = r_norm / max(s_norm, eps)\n    log_ratio = np.log(ratio) if ratio > 0 else 0.0\n    \n    # Determine update factor based on the ratio and iteration\n    t = tau(k, c, p)\n    # Base factor: more aggressive updates when residuals are imbalanced\n    # Use a sigmoid-like function to bound the factor between 1.1 and 1.5 early, and 1.05 and 1.2 later\n    base_aggression = 1.5 - 0.4 * min(k / 100.0, 1.0)\n    # Adjust factor based on log ratio magnitude\n    if abs(log_ratio) > 0.1:\n        # When ratio is far from 1, be more aggressive\n        factor = base_aggression + 0.1 * min(abs(log_ratio), 2.0)\n    else:\n        factor = 1.05 + t\n    \n    # Ensure factor is within reasonable bounds\n    factor = min(max(factor, 1.01), 2.0)\n    \n    # Update decision\n    if r_norm > dynamic_mu * max(s_norm, eps):\n        return rho * factor, t, \"mul\"\n    elif s_norm > dynamic_mu * max(r_norm, eps):\n        return rho / factor, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, avoiding division by zero\n    ratio = (r_norm + eps) / (s_norm + eps)\n    \n    # Target ratio is 1, so we want ratio to be close to 1\n    # If ratio > mu, primal residual is too large -> increase rho\n    # If ratio < 1/mu, dual residual is too large -> decrease rho\n    # Use a smoother update factor based on sqrt(ratio) dampened by t\n    # Cap the maximum adjustment to avoid extreme changes\n    if ratio > mu:\n        # Increase rho by factor proportional to sqrt(ratio)\n        # But dampen with t to avoid large jumps in later iterations\n        adj = np.sqrt(ratio)\n        # Bound adjustment between 1.0 and 2.0\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho * fac, t, \"mul\"\n    elif ratio < 1.0 / mu:\n        # Decrease rho\n        adj = np.sqrt(1.0 / ratio)\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho / fac, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, I notice it's using a simple approach that updates rho based on the ratio of primal to dual residual, with a smooth adjustment using sqrt(ratio) and dampening by tau. However, the fitness score has declined from 0.0826 to 0.0767, which suggests this approach may not be as effective as previous versions.\n\nThe top-performing programs (with score 0.0826) have several key features:\n1. They adjust mu based on iteration (more aggressive early, conservative later)\n2. They use different base factors for updates depending on iteration\n3. They ensure updates are meaningful by setting a minimum factor (1.05)\n4. They bound rho between 1e-6 and 1e6 for numerical stability\n5. They compute both r_ratio and s_ratio to check both directions\n\nThe current program lacks these features, which might explain the lower fitness. Let's incorporate these successful strategies while keeping the code concise (under 500 characters).\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, avoiding division by zero\n    ratio = (r_norm + eps) / (s_norm + eps)\n    \n    # Target ratio is 1, so we want ratio to be close to 1\n    # If ratio > mu, primal residual is too large -> increase rho\n    # If ratio < 1/mu, dual residual is too large -> decrease rho\n    # Use a smoother update factor based on sqrt(ratio) dampened by t\n    # Cap the maximum adjustment to avoid extreme changes\n    if ratio > mu:\n        # Increase rho by factor proportional to sqrt(ratio)\n        # But dampen with t to avoid large jumps in later iterations\n        adj = np.sqrt(ratio)\n        # Bound adjustment between 1.0 and 2.0\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho * fac, t, \"mul\"\n    elif ratio < 1.0 / mu:\n        # Decrease rho\n        adj = np.sqrt(1.0 / ratio)\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho / fac, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute both ratios\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    t = tau(k, c, p)\n    # Update logic\n    if r_ratio > effective_mu:\n        factor = max(base_factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        factor = max(base_factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Bound rho for numerical stability\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Auxiliary value\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThis change incorporates the successful strategies from the top-performing programs:\n1. Dynamic mu adjustment: more aggressive early (k < 10) with mu=2.0, then mu=3.0\n2. Both r_ratio and s_ratio are computed to check imbalances in both directions\n3. Base factor decreases with iterations: 1.5 for early, 1.2 for middle, 1.1 for late\n4. Minimum factor of 1.05 ensures meaningful updates\n5. Rho is bounded between 1e-6 and 1e6\n6. The auxiliary value is set to the larger ratio for logging\n\nThis approach should help achieve faster convergence by being more responsive to imbalances early on while maintaining stability later. The code is also concise and should fit within the character limit."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}