{"id": "d9e7d04a-83e4-429d-805a-bb06b693483e", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base factor based on iteration count\n    # Early iterations: more aggressive updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to make updates diminish over time\n    t = tau(k, c, p)\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using the ratio and its reciprocal\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "be79e662-6942-48fe-a8d4-5b7783fdb933", "generation": 2, "timestamp": 1768219595.328407, "iteration_found": 42, "metrics": {"combined_score": 0.08292338142301477, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08292338142301477}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "0.114s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 62 lines with 63 lines", "parent_metrics": {"combined_score": 0.07116176210042219, "metrics": {"converged": true, "iters": 14, "combined_score": 0.07116176210042219}, "artifacts": {"status": "CONVERGED", "iterations": 14, "eval_time": "0.019s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in numerical optimization and ADMM algorithms.\n\nYour task is to improve the function update_rho(rho, k, r_norm, s_norm, ...)\nused to adaptively update the ADMM penalty parameter.\n\nGoals:\n- Achieve faster convergence (fewer ADMM iterations)\n- Maintain numerical stability (avoid oscillating rho)\n- Balance primal and dual residuals efficiently\n\nConstraints:\n- You may ONLY modify the body of update_rho and helper functions in initial_program.py\n- The function signature and return types must remain unchanged\n- The code must be deterministic and numerically safe\n\nHints:\n- Consider using ratios or log-ratios of r_norm and s_norm\n- Early iterations may benefit from aggressive updates\n- Later iterations should favor stability\n- Piecewise or stateful strategies are allowed\n", "user": "# Current Program Information\n- Fitness: 0.0712\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0829 \u2192 0.0712. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 56 lines with 65 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.031s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 45 lines with 64 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.045s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 75 lines with 92 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292794781575066}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.016s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    # Also, if residuals are large, be more sensitive\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration and residual scale\n    if k < 5:\n        # Very early: very aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    # Use a smoother approach: compute a weighted decision\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # The factor should be between base_factor and 1.0, but we want >1\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292794781575066}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.016s'})\n\n### Program 2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Adjust factor with diminishing component\n    # We want to reduce the factor as iterations increase\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.045s'})\n\n### Program 3 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Use a fixed mu for simplicity (like the best performer)\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information (like the best performer)\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.031s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0826)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early (smaller threshold)\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Check conditions\n    if ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0827)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Dynamic threshold: start with a lower value to encourage updates early,\n    # then gradually increase to mu for stability\n    # This helps to balance the residuals faster in early iterations\n    if k < 5:\n        effective_mu = 2.0\n    elif k < 15:\n        effective_mu = 2.5\n    else:\n        effective_mu = mu\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.6\n    elif k < 15:\n        base_factor = 1.3\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor with diminishing component\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using the ratio and its reciprocal\n    if ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0829, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    # Also, if residuals are large, be more sensitive\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration and residual scale\n    if k < 5:\n        # Very early: very aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    # Use a smoother approach: compute a weighted decision\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # The factor should be between base_factor and 1.0, but we want >1\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0826, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust threshold based on iteration: more aggressive early\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute ratio\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to make updates diminish over time\n    t = tau(k, c, p)\n    factor = max(base_factor - t, 1.05)\n    \n    # Update decision\n    if ratio > effective_mu:\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Bound rho for numerical stability\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use ratio as auxiliary value\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 3 (Score: 0.0767, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of primal to dual residual\n    ratio = r_norm / (s_norm + eps)\n    \n    # Target ratio is 1 (balanced residuals)\n    # Use log ratio to determine update direction and magnitude\n    log_ratio = np.log(ratio + 1e-16)  # Add small number to avoid log(0)\n    \n    # Determine update magnitude: more aggressive early, conservative later\n    # Use tau to control step size\n    t = tau(k, c, p)\n    \n    # Scale factor based on log ratio and iteration\n    # Clamp the exponent to prevent extreme updates\n    exponent = t * np.tanh(log_ratio)\n    \n    # Bound the update factor between 0.5 and 2.0\n    update_factor = np.exp(exponent)\n    update_factor = np.clip(update_factor, 0.5, 2.0)\n    \n    # Decide whether to update based on how far ratio is from 1\n    # If ratio is within [1/mu, mu], keep rho unchanged\n    if ratio > mu:\n        new_rho = rho * update_factor\n        mode = \"mul\"\n    elif ratio < 1.0/mu:\n        new_rho = rho / update_factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Additional safeguard: prevent rho from becoming too large or too small\n    if new_rho > 1e6:\n        new_rho = 1e6\n        mode = \"clip\"\n    elif new_rho < 1e-6:\n        new_rho = 1e-6\n        mode = \"clip\"\n    \n    # Use log_ratio as auxiliary value\n    aux = log_ratio\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Dynamic threshold: start larger, decrease to mu\n    # Using exponential decay for smooth transition\n    mu_adj = mu * (1.0 + 2.0 * np.exp(-0.1 * k))\n    \n    # Compute ratio safely\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on ratio, but bounded\n    # More aggressive early, conservative later\n    if ratio > mu_adj:\n        # Increase rho\n        fac = np.sqrt(ratio)\n        fac = min(fac, 1.5)  # Bound the factor\n        # Scale aggressiveness with iteration\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho * fac\n        mode = \"mul\"\n    elif 1.0 / ratio > mu_adj:\n        # Decrease rho\n        fac = np.sqrt(1.0 / ratio)\n        fac = min(fac, 1.5)\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho / fac\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to prevent extreme values\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    return new_rho, t, mode\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, I notice it's more complex than the top performers and has a lower fitness score (0.0712 vs 0.0829). The top performers are simpler and use a more straightforward approach with piecewise factors based on iteration count. They also use a fixed mu threshold and adjust the update factor with tau.\n\nThe current program uses a dynamic threshold mu_adj that starts larger and decreases, which might be causing instability. Also, it uses sqrt(ratio) to determine the factor, which could be too aggressive or not aggressive enough.\n\nLet's simplify the approach to match the best performers while incorporating some of their successful strategies:\n\n1. Use a fixed mu threshold (3.0) as in the original ADMM paper\n2. Use piecewise base factors based on iteration count for aggressive early updates\n3. Use tau to diminish updates over time\n4. Keep the ratio check simple\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Dynamic threshold: start larger, decrease to mu\n    # Using exponential decay for smooth transition\n    mu_adj = mu * (1.0 + 2.0 * np.exp(-0.1 * k))\n    \n    # Compute ratio safely\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on ratio, but bounded\n    # More aggressive early, conservative later\n    if ratio > mu_adj:\n        # Increase rho\n        fac = np.sqrt(ratio)\n        fac = min(fac, 1.5)  # Bound the factor\n        # Scale aggressiveness with iteration\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho * fac\n        mode = \"mul\"\n    elif 1.0 / ratio > mu_adj:\n        # Decrease rho\n        fac = np.sqrt(1.0 / ratio)\n        fac = min(fac, 1.5)\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho / fac\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to prevent extreme values\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    return new_rho, t, mode\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base factor based on iteration count\n    # Early iterations: more aggressive updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to make updates diminish over time\n    t = tau(k, c, p)\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using the ratio and its reciprocal\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThis change simplifies the update strategy to match the best performers, which have shown to achieve better fitness scores. The key improvements are:\n1. Removed the dynamic threshold (mu_adj) which might be causing instability\n2. Used a simple piecewise base factor that's more aggressive early and conservative later\n3. Used tau to diminish updates over time, which helps with convergence\n4. The factor is bounded to prevent too small updates (min 1.05)\n5. The ratio is used as auxiliary output, which is consistent with top performers\n\nThis approach should lead to faster convergence by being more aggressive in early iterations while maintaining stability in later iterations. The fixed mu threshold (3.0) is standard in ADMM and has worked well in the top performers."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}