{"id": "088e9772-4414-40a3-aa25-3df45f2724f9", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early, conservative later\n    if k < 10:\n        effective_mu = 2.0  # Lower threshold to update more frequently early\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base update factor based on iteration\n    # Early: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Check if we need to update\n    if ratio > effective_mu:\n        # Primal residual too large: increase rho\n        # Make factor diminish with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05 for meaningful updates\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Dual residual too large: decrease rho\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Balanced residuals\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to maintain numerical stability\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "be79e662-6942-48fe-a8d4-5b7783fdb933", "generation": 2, "timestamp": 1768219263.776264, "iteration_found": 17, "metrics": {"combined_score": 0.08261401069195577, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08261401069195577}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "0.017s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 62 lines with 75 lines", "parent_metrics": {"combined_score": 0.07116176210042219, "metrics": {"converged": true, "iters": 14, "combined_score": 0.07116176210042219}, "artifacts": {"status": "CONVERGED", "iterations": 14, "eval_time": "0.019s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in numerical optimization and ADMM algorithms.\n\nYour task is to improve the function update_rho(rho, k, r_norm, s_norm, ...)\nused to adaptively update the ADMM penalty parameter.\n\nGoals:\n- Achieve faster convergence (fewer ADMM iterations)\n- Maintain numerical stability (avoid oscillating rho)\n- Balance primal and dual residuals efficiently\n\nConstraints:\n- You may ONLY modify the body of update_rho and helper functions in initial_program.py\n- The function signature and return types must remain unchanged\n- The code must be deterministic and numerically safe\n\nHints:\n- Consider using ratios or log-ratios of r_norm and s_norm\n- Early iterations may benefit from aggressive updates\n- Later iterations should favor stability\n- Piecewise or stateful strategies are allowed\n", "user": "# Current Program Information\n- Fitness: 0.0712\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0767 \u2192 0.0712. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 37 lines with 68 lines\n- Metrics: combined_score: 0.0767, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.07669310862140852}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '0.010s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 10 lines with 19 lines\nChange 2: Replace 19 lines with 25 lines\n- Metrics: combined_score: 0.0767, metrics: {'converged': True, 'iters': 13, 'combined_score': 0.0766992980527246}, artifacts: {'status': 'CONVERGED', 'iterations': 13, 'eval_time': '0.007s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 37 lines with 77 lines\n- Metrics: combined_score: 0.0826, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08261401069195577}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.008s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0826)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration to be more aggressive early on\n    # For early iterations, use a smaller threshold to update more frequently\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # The adjustment factor should be between base_factor and 1/base_factor\n    # But we want to make sure updates are not too small\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to penalize primal infeasibility more\n        # Use a factor that decreases with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to penalize dual infeasibility more\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0826), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08261401069195577}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.008s'})\n\n### Program 2 (Score: 0.0767)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, avoiding division by zero\n    ratio = (r_norm + eps) / (s_norm + eps)\n    \n    # Target ratio is 1, so we want ratio to be close to 1\n    # If ratio > mu, primal residual is too large -> increase rho\n    # If ratio < 1/mu, dual residual is too large -> decrease rho\n    # Use a smoother update factor based on sqrt(ratio) dampened by t\n    # Cap the maximum adjustment to avoid extreme changes\n    if ratio > mu:\n        # Increase rho by factor proportional to sqrt(ratio)\n        # But dampen with t to avoid large jumps in later iterations\n        adj = np.sqrt(ratio)\n        # Bound adjustment between 1.0 and 2.0\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho * fac, t, \"mul\"\n    elif ratio < 1.0 / mu:\n        # Decrease rho\n        adj = np.sqrt(1.0 / ratio)\n        adj = min(adj, 2.0)\n        fac = 1.0 + t * (adj - 1.0)\n        return rho / fac, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n\n```\nKey features: Performs well on combined_score (0.0767), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.0766992980527246}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '0.007s'})\n\n### Program 3 (Score: 0.0767)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of primal to dual residual\n    ratio = r_norm / (s_norm + eps)\n    \n    # Target ratio is 1 (balanced residuals)\n    # Use log ratio to determine update direction and magnitude\n    log_ratio = np.log(ratio + 1e-16)  # Add small number to avoid log(0)\n    \n    # Determine update magnitude: more aggressive early, conservative later\n    # Use tau to control step size\n    t = tau(k, c, p)\n    \n    # Scale factor based on log ratio and iteration\n    # Clamp the exponent to prevent extreme updates\n    exponent = t * np.tanh(log_ratio)\n    \n    # Bound the update factor between 0.5 and 2.0\n    update_factor = np.exp(exponent)\n    update_factor = np.clip(update_factor, 0.5, 2.0)\n    \n    # Decide whether to update based on how far ratio is from 1\n    # If ratio is within [1/mu, mu], keep rho unchanged\n    if ratio > mu:\n        new_rho = rho * update_factor\n        mode = \"mul\"\n    elif ratio < 1.0/mu:\n        new_rho = rho / update_factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Additional safeguard: prevent rho from becoming too large or too small\n    if new_rho > 1e6:\n        new_rho = 1e6\n        mode = \"clip\"\n    elif new_rho < 1e-6:\n        new_rho = 1e-6\n        mode = \"clip\"\n    \n    # Use log_ratio as auxiliary value\n    aux = log_ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0767), Performs well on metrics ({'converged': True, 'iters': 13, 'combined_score': 0.07669310862140852}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 13, 'eval_time': '0.010s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0766)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef compute_adjustment_factor(ratio, k, base=0.85):\n    \"\"\"\n    Compute adjustment factor based on residual ratio and iteration.\n    \"\"\"\n    # Diminishing influence over iterations\n    t = tau(k)\n    # Target ratio is 1, so if ratio > 1, rho should increase\n    # Use sqrt to make adjustments more moderate\n    # Clip the adjustment to prevent extreme changes\n    adj = np.sqrt(ratio)\n    # Bound the adjustment between 0.5 and 2.0\n    adj = np.clip(adj, 0.5, 2.0)\n    # Blend with base factor, with diminishing influence over iterations\n    factor = base + (adj - base) * np.exp(-k / 10.0)\n    return factor\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # If both residuals are very small, keep rho\n    if r_norm < eps and s_norm < eps:\n        return rho, 0.0, \"keep\"\n    \n    # Determine if we need to adjust rho\n    # Use a dynamic threshold that tightens over iterations\n    # Early iterations: be more aggressive (larger mu)\n    # Later iterations: be more conservative (smaller mu)\n    dynamic_mu = mu * (1.0 + 2.0 * np.exp(-k / 5.0))\n    \n    if ratio > dynamic_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to prioritize primal feasibility\n        factor = compute_adjustment_factor(ratio, k)\n        new_rho = rho * factor\n        return new_rho, factor, \"mul\"\n    elif 1.0 / ratio > dynamic_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to prioritize dual feasibility\n        factor = compute_adjustment_factor(1.0 / ratio, k)\n        new_rho = rho / factor\n        return new_rho, factor, \"div\"\n    else:\n        # Residuals are balanced\n        return rho, 1.0, \"keep\"\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0738)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration to be more aggressive early, conservative later\n    # Early iterations: lower threshold to trigger updates more often\n    # Later iterations: higher threshold to avoid oscillations\n    if k < 10:\n        mu_adj = 2.0  # More sensitive to imbalances\n    elif k < 30:\n        mu_adj = 3.0\n    else:\n        mu_adj = 4.0  # More conservative\n    \n    # Compute adjustment factor that is larger when residuals are very imbalanced\n    t = tau(k, c, p)\n    # Base factor between 1.1 and 1.5, diminishing with iterations\n    base_factor = 1.5 - 0.4 * min(k / 50.0, 1.0)\n    # Adjust based on the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    if ratio > 1:\n        # If primal is larger than dual, we may want to increase rho more aggressively\n        # But don't let factor exceed 2.0\n        factor = min(base_factor + 0.1 * min(ratio - 1, 5.0), 2.0)\n    else:\n        factor = base_factor\n    \n    # Check conditions with adjusted mu\n    if r_norm > mu_adj * max(s_norm, eps):\n        return rho * factor, t, \"mul\"\n    elif s_norm > mu_adj * max(r_norm, eps):\n        return rho / factor, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0767, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of primal to dual residual\n    ratio = r_norm / (s_norm + eps)\n    \n    # Target ratio is 1 (balanced residuals)\n    # Use log ratio to determine update direction and magnitude\n    log_ratio = np.log(ratio + 1e-16)  # Add small number to avoid log(0)\n    \n    # Determine update magnitude: more aggressive early, conservative later\n    # Use tau to control step size\n    t = tau(k, c, p)\n    \n    # Scale factor based on log ratio and iteration\n    # Clamp the exponent to prevent extreme updates\n    exponent = t * np.tanh(log_ratio)\n    \n    # Bound the update factor between 0.5 and 2.0\n    update_factor = np.exp(exponent)\n    update_factor = np.clip(update_factor, 0.5, 2.0)\n    \n    # Decide whether to update based on how far ratio is from 1\n    # If ratio is within [1/mu, mu], keep rho unchanged\n    if ratio > mu:\n        new_rho = rho * update_factor\n        mode = \"mul\"\n    elif ratio < 1.0/mu:\n        new_rho = rho / update_factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Additional safeguard: prevent rho from becoming too large or too small\n    if new_rho > 1e6:\n        new_rho = 1e6\n        mode = \"clip\"\n    elif new_rho < 1e-6:\n        new_rho = 1e-6\n        mode = \"clip\"\n    \n    # Use log_ratio as auxiliary value\n    aux = log_ratio\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0712, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Adjust mu to be tighter as iterations increase\n    # Start with a larger threshold early, then reduce to enforce balance\n    mu_adj = mu * (1.0 + 2.0 * np.exp(-0.1 * k))\n    \n    # Dynamic factor: more aggressive early, conservative later\n    # Base factor between 1.1 and 1.5 when k=0, decreasing to around 1.05\n    base_factor = 1.5 - 0.4 * np.tanh(0.1 * k)\n    fac = base_factor + t\n    \n    # Check if residuals are imbalanced\n    if r_norm > mu_adj * max(s_norm, eps):\n        return rho * fac, t, \"mul\"\n    \n    if s_norm > mu_adj * max(r_norm, eps):\n        return rho / fac, t, \"div\"\n    \n    return rho, t, \"keep\"\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 3 (Score: 0.0738, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration to be more aggressive early, conservative later\n    # Early iterations: lower threshold to trigger updates more often\n    # Later iterations: higher threshold to avoid oscillations\n    if k < 10:\n        mu_adj = 2.0  # More sensitive to imbalances\n    elif k < 30:\n        mu_adj = 3.0\n    else:\n        mu_adj = 4.0  # More conservative\n    \n    # Compute adjustment factor that is larger when residuals are very imbalanced\n    t = tau(k, c, p)\n    # Base factor between 1.1 and 1.5, diminishing with iterations\n    base_factor = 1.5 - 0.4 * min(k / 50.0, 1.0)\n    # Adjust based on the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    if ratio > 1:\n        # If primal is larger than dual, we may want to increase rho more aggressively\n        # But don't let factor exceed 2.0\n        factor = min(base_factor + 0.1 * min(ratio - 1, 5.0), 2.0)\n    else:\n        factor = base_factor\n    \n    # Check conditions with adjusted mu\n    if r_norm > mu_adj * max(s_norm, eps):\n        return rho * factor, t, \"mul\"\n    elif s_norm > mu_adj * max(r_norm, eps):\n        return rho / factor, t, \"div\"\n    else:\n        return rho, t, \"keep\"\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Dynamic threshold: start larger, decrease to mu\n    # Using exponential decay for smooth transition\n    mu_adj = mu * (1.0 + 2.0 * np.exp(-0.1 * k))\n    \n    # Compute ratio safely\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on ratio, but bounded\n    # More aggressive early, conservative later\n    if ratio > mu_adj:\n        # Increase rho\n        fac = np.sqrt(ratio)\n        fac = min(fac, 1.5)  # Bound the factor\n        # Scale aggressiveness with iteration\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho * fac\n        mode = \"mul\"\n    elif 1.0 / ratio > mu_adj:\n        # Decrease rho\n        fac = np.sqrt(1.0 / ratio)\n        fac = min(fac, 1.5)\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho / fac\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to prevent extreme values\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    return new_rho, t, mode\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the evolution history, the best performing program achieved a combined_score of 0.0826 with 12 iterations. The current program has a fitness of 0.0712, which is lower. The key seems to be balancing aggressive updates early for faster convergence while maintaining stability later.\n\nThe top program (Program 1) uses:\n1. Different mu thresholds for early vs later iterations (2.0 for k<10, else mu)\n2. Different base factors for different iteration ranges (1.5, 1.2, 1.1)\n3. Uses tau to make updates diminishing\n4. Ensures factor is at least 1.05\n\nThe current program uses a dynamic mu_adj that decays exponentially, which might be too aggressive in later iterations. Also, the update factor calculation uses sqrt(ratio) which can be too sensitive.\n\nLet's aim for a simpler, more effective approach:\n1. Early iterations should update more aggressively to reach a good rho quickly\n2. Later iterations should be more conservative to avoid oscillations\n3. Use clear thresholds and factors\n\nHere's a revised approach that combines ideas from the best programs:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Dynamic threshold: start larger, decrease to mu\n    # Using exponential decay for smooth transition\n    mu_adj = mu * (1.0 + 2.0 * np.exp(-0.1 * k))\n    \n    # Compute ratio safely\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on ratio, but bounded\n    # More aggressive early, conservative later\n    if ratio > mu_adj:\n        # Increase rho\n        fac = np.sqrt(ratio)\n        fac = min(fac, 1.5)  # Bound the factor\n        # Scale aggressiveness with iteration\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho * fac\n        mode = \"mul\"\n    elif 1.0 / ratio > mu_adj:\n        # Decrease rho\n        fac = np.sqrt(1.0 / ratio)\n        fac = min(fac, 1.5)\n        fac = 1.0 + (fac - 1.0) * (1.0 - 0.5 * t)\n        new_rho = rho / fac\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to prevent extreme values\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    return new_rho, t, mode\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early, conservative later\n    if k < 10:\n        effective_mu = 2.0  # Lower threshold to update more frequently early\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base update factor based on iteration\n    # Early: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Check if we need to update\n    if ratio > effective_mu:\n        # Primal residual too large: increase rho\n        # Make factor diminish with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05 for meaningful updates\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Dual residual too large: decrease rho\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Balanced residuals\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to maintain numerical stability\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThis change:\n1. Uses a clear threshold adjustment: effective_mu is 2.0 for first 10 iterations, then 3.0 (mu)\n2. Uses different base factors for different iteration ranges (1.5, 1.2, 1.1) which matches the best program\n3. Uses tau to make updates diminishing, ensuring factor decreases over time\n4. Ensures factor is at least 1.05 to prevent updates from becoming too small\n5. Simpler and more direct than the current approach, which should lead to better convergence\n\nThis approach is similar to the top-performing program (Program 1) which had the best score of 0.0826. By adopting its core strategy, we can potentially achieve similar performance. The main difference is that we're using a slightly different way to compute the factor (base_factor - t vs base_factor in the original), but this should still work well.\n\nNote: The original top program also had a line to compute r_ratio and s_ratio, but we're using a simpler approach with just ratio. This should be fine since we're checking both conditions with ratio and 1/ratio."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}