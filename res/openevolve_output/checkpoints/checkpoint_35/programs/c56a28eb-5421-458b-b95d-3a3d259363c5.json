{"id": "c56a28eb-5421-458b-b95d-3a3d259363c5", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration to be more aggressive early on\n    # For early iterations, use a smaller threshold to update more frequently\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # The adjustment factor should be between base_factor and 1/base_factor\n    # But we want to make sure updates are not too small\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to penalize primal infeasibility more\n        # Use a factor that decreases with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to penalize dual infeasibility more\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "e3e7b7e1-1592-4d78-8c9c-6a76f7a88c15", "generation": 1, "timestamp": 1768219133.109437, "iteration_found": 7, "metrics": {"combined_score": 0.08261401069195577, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08261401069195577}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "0.008s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 37 lines with 77 lines", "parent_metrics": {"combined_score": 0.043007227611818806, "metrics": {"converged": true, "iters": 23, "combined_score": 0.043007227611818806}, "artifacts": {"status": "CONVERGED", "iterations": 23, "eval_time": "0.021s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in numerical optimization and ADMM algorithms.\n\nYour task is to improve the function update_rho(rho, k, r_norm, s_norm, ...)\nused to adaptively update the ADMM penalty parameter.\n\nGoals:\n- Achieve faster convergence (fewer ADMM iterations)\n- Maintain numerical stability (avoid oscillating rho)\n- Balance primal and dual residuals efficiently\n\nConstraints:\n- You may ONLY modify the body of update_rho and helper functions in initial_program.py\n- The function signature and return types must remain unchanged\n- The code must be deterministic and numerically safe\n\nHints:\n- Consider using ratios or log-ratios of r_norm and s_norm\n- Early iterations may benefit from aggressive updates\n- Later iterations should favor stability\n- Piecewise or stateful strategies are allowed\n", "user": "# Current Program Information\n- Fitness: 0.0430\n- Feature coordinates: \n- Focus areas: - Fitness unchanged at 0.0430\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 1\n- Changes: Unknown changes\n- Metrics: combined_score: 0.0430, metrics: {'converged': True, 'iters': 23, 'combined_score': 0.043007227611818806}, artifacts: {'status': 'CONVERGED', 'iterations': 23, 'eval_time': '0.021s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0430)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    fac = 0.85 + t\n\n    if r_norm > mu * max(s_norm, eps):\n        return rho * fac, t, \"mul\"\n\n    if s_norm > mu * max(r_norm, eps):\n        return rho / fac, t, \"div\"\n\n    return rho, t, \"keep\"\n\n```\nKey features: Performs well on combined_score (0.0430), Performs well on metrics ({'converged': True, 'iters': 23, 'combined_score': 0.043007227611818806}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 23, 'eval_time': '0.021s'})\n\n\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    fac = 0.85 + t\n\n    if r_norm > mu * max(s_norm, eps):\n        return rho * fac, t, \"mul\"\n\n    if s_norm > mu * max(r_norm, eps):\n        return rho / fac, t, \"div\"\n\n    return rho, t, \"keep\"\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, the `update_rho` function uses a fixed threshold `mu=3.0` and a diminishing step size `t` to adjust `rho`. The adjustment factor `fac = 0.85 + t` is always between 0.85 and 1.85, which can be too conservative, especially in early iterations. This may lead to slower convergence.\n\nTo improve convergence speed while maintaining stability, we can:\n1. Make the update more aggressive in early iterations and more conservative later\n2. Use a dynamic threshold that adapts to the iteration count\n3. Adjust the factor based on the ratio of residuals to balance primal and dual residuals more effectively\n\nHere's a revised approach:\n- For early iterations (k < 10), use a larger adjustment factor to quickly find a good rho\n- For later iterations, use a smaller adjustment to avoid oscillations\n- Use the ratio r_norm/s_norm to determine the update direction and magnitude\n- Ensure numerical stability with proper handling of small residuals\n\nLet's implement these changes:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    fac = 0.85 + t\n\n    if r_norm > mu * max(s_norm, eps):\n        return rho * fac, t, \"mul\"\n\n    if s_norm > mu * max(r_norm, eps):\n        return rho / fac, t, \"div\"\n\n    return rho, t, \"keep\"\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration to be more aggressive early on\n    # For early iterations, use a smaller threshold to update more frequently\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # The adjustment factor should be between base_factor and 1/base_factor\n    # But we want to make sure updates are not too small\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Increase rho to penalize primal infeasibility more\n        # Use a factor that decreases with iterations\n        factor = base_factor - t\n        # Ensure factor is at least 1.05\n        factor = max(factor, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        # Decrease rho to penalize dual infeasibility more\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThis implementation:\n1. Uses a dynamic threshold that's more aggressive in early iterations (k < 10) to allow more frequent updates\n2. Adjusts the update factor based on iteration count: larger updates early, smaller later\n3. Uses the ratio of residuals directly to make decisions, which is more precise than fixed thresholds\n4. Ensures numerical stability by bounding rho within reasonable limits\n5. Returns the maximum ratio as auxiliary information for logging\n\nHowever, we need to be careful about the factor calculation. The original approach used `fac = 0.85 + t` which always produces numbers >= 0.85. Our approach uses `base_factor - t` which could become less than 1.0 if t is too large, which would invert the update direction. To prevent this, we set a minimum of 1.05.\n\nThis should lead to faster convergence by making more aggressive adjustments in early iterations while maintaining stability in later iterations. The dynamic threshold and factor adjustments should help balance primal and dual residuals more effectively, reducing the number of ADMM iterations required for convergence."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}