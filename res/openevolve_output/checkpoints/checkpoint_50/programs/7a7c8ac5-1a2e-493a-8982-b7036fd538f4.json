{"id": "7a7c8ac5-1a2e-493a-8982-b7036fd538f4", "code": "# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute both ratios for balanced decision\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using both ratios\n    if r_ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the larger ratio as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n", "language": "python", "parent_id": "2f96955a-a9a2-44eb-bd95-e3fa6f8cfe12", "generation": 4, "timestamp": 1768219664.5593548, "iteration_found": 48, "metrics": {"combined_score": 0.08292338142301477, "metrics": {"converged": true, "iters": 12, "combined_score": 0.08292338142301477}, "artifacts": {"status": "CONVERGED", "iterations": 12, "eval_time": "0.023s"}}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 81 lines with 66 lines", "parent_metrics": {"combined_score": 0.07615792999274147, "metrics": {"converged": true, "iters": 13, "combined_score": 0.07615792999274147}, "artifacts": {"status": "CONVERGED", "iterations": 13, "eval_time": "0.024s"}}, "island": 0}, "prompts": {"diff_user": {"system": "You are an expert in numerical optimization and ADMM algorithms.\n\nYour task is to improve the function update_rho(rho, k, r_norm, s_norm, ...)\nused to adaptively update the ADMM penalty parameter.\n\nGoals:\n- Achieve faster convergence (fewer ADMM iterations)\n- Maintain numerical stability (avoid oscillating rho)\n- Balance primal and dual residuals efficiently\n\nConstraints:\n- You may ONLY modify the body of update_rho and helper functions in initial_program.py\n- The function signature and return types must remain unchanged\n- The code must be deterministic and numerically safe\n\nHints:\n- Consider using ratios or log-ratios of r_norm and s_norm\n- Early iterations may benefit from aggressive updates\n- Later iterations should favor stability\n- Piecewise or stateful strategies are allowed\n", "user": "# Current Program Information\n- Fitness: 0.0762\n- Feature coordinates: \n- Focus areas: - Fitness declined: 0.0829 \u2192 0.0762. Consider revising recent changes.\n- No feature coordinates\n- Consider simplifying - code length exceeds 500 characters\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Change 1: Replace 71 lines with 64 lines\nChange 2: Replace 15 lines with \n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.012s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 2\n- Changes: Change 1: Replace 45 lines with 64 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.045s'}\n- Outcome: Improvement in all metrics\n\n### Attempt 1\n- Changes: Change 1: Replace 75 lines with 92 lines\n- Metrics: combined_score: 0.0829, metrics: {'converged': True, 'iters': 12, 'combined_score': 0.08292794781575066}, artifacts: {'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.016s'}\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Dynamic threshold based on iteration and residual magnitude\n    # Early iterations: be more aggressive with a lower threshold\n    # Also, if residuals are large, be more sensitive\n    residual_scale = np.log10(max(r_norm, s_norm, eps) + 1.0)\n    # Scale mu based on iteration and residual scale\n    if k < 5:\n        # Very early: very aggressive\n        effective_mu = 1.5 + 0.1 * residual_scale\n        base_factor = 2.0\n    elif k < 15:\n        # Early: moderately aggressive\n        effective_mu = 2.0 + 0.2 * residual_scale\n        base_factor = 1.5\n    else:\n        # Later: more conservative\n        effective_mu = mu + 0.3 * residual_scale\n        base_factor = 1.2\n    \n    # Cap effective_mu to prevent being too sensitive\n    effective_mu = min(effective_mu, 10.0)\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    \n    # Determine update based on both ratios\n    # Use a smoother approach: compute a weighted decision\n    if r_ratio > effective_mu:\n        # Primal residual is too large relative to dual residual\n        # Make the update factor depend on how large the ratio is\n        excess_ratio = min(r_ratio / effective_mu, 5.0)\n        # The factor should be between base_factor and 1.0, but we want >1\n        # Use a logarithmic scaling\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        # Apply diminishing returns with t\n        factor = max(factor - t, 1.05)\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual is too large relative to primal residual\n        excess_ratio = min(s_ratio / effective_mu, 5.0)\n        factor = 1.0 + (base_factor - 1.0) * np.log1p(excess_ratio - 1.0) / np.log1p(4.0)\n        factor = max(factor - t, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use a combined measure as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292794781575066}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.016s'})\n\n### Program 2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    t = tau(k, c, p)\n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Adjust factor with diminishing component\n    # We want to reduce the factor as iterations increase\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.045s'})\n\n### Program 3 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Performs well on combined_score (0.0829), Performs well on metrics ({'converged': True, 'iters': 12, 'combined_score': 0.08292338142301477}), Performs well on artifacts ({'status': 'CONVERGED', 'iterations': 12, 'eval_time': '0.012s'})\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute both ratios for balanced decision\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using both ratios\n    if r_ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the larger ratio as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n### Program D2 (Score: 0.0829)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of residuals, handling small values\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor with diminishing component\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 to avoid too small updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using the standard mu threshold\n    if ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    # Also, prevent very large jumps by limiting the change per iteration\n    max_change = 10.0\n    if new_rho > rho * max_change:\n        new_rho = rho * max_change\n    elif new_rho < rho / max_change:\n        new_rho = rho / max_change\n    \n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the ratio as auxiliary information\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nKey features: Alternative approach to combined_score, Alternative approach to metrics\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0761, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n\n    t = tau(k, c, p)\n    # Adjust mu based on iteration: start more permissive, become stricter\n    # For early iterations (k < 10), use a larger threshold to allow exploration\n    if k < 10:\n        dynamic_mu = mu * 2.0\n    else:\n        # Gradually tighten to mu by iteration 50\n        dynamic_mu = mu * (1.0 + np.exp(-0.1 * (k - 10)))\n    \n    # Compute the ratio of residuals\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration and ratio\n    # Early iterations: more aggressive (up to 2.0), later: more conservative (up to 1.3)\n    if k < 10:\n        base_factor = 1.8\n    elif k < 30:\n        base_factor = 1.5\n    else:\n        base_factor = 1.2\n    \n    # Adjust factor based on how far ratio is from 1, but bounded\n    # Use a smooth function: factor = base_factor + 0.1 * min(|log(ratio)|, 3.0)\n    # This makes updates larger when residuals are more imbalanced\n    if ratio > 0:\n        log_ratio = np.log(ratio)\n        adjustment = 0.1 * min(abs(log_ratio), 3.0)\n    else:\n        adjustment = 0.0\n    factor = base_factor + adjustment\n    \n    # Clip factor to reasonable bounds\n    factor = min(max(factor, 1.05), 2.5)\n    \n    # Update decision\n    if ratio > dynamic_mu:\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > dynamic_mu:\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Ensure rho stays within bounds\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    return new_rho, t, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 2 (Score: 0.0826, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust mu based on iteration: more aggressive early (update more frequently)\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute ratios with safeguards\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration: larger updates early, smaller later\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau for additional damping\n    t = tau(k, c, p)\n    \n    # Update logic\n    if r_ratio > effective_mu:\n        # Primal residual too large: increase rho\n        # Combine base factor with tau damping: factor decreases with iterations\n        factor = base_factor - t\n        factor = max(factor, 1.05)  # Ensure minimum update\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > effective_mu:\n        # Dual residual too large: decrease rho\n        factor = base_factor - t\n        factor = max(factor, 1.05)\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Balanced residuals\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Numerical stability: bound rho to prevent extreme values\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Auxiliary value: use the larger ratio for logging\n    aux = r_ratio if r_ratio > s_ratio else s_ratio\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n### Inspiration 3 (Score: 0.0826, Type: Exploratory)\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Adjust threshold based on iteration: more aggressive early\n    if k < 10:\n        effective_mu = 2.0\n    else:\n        effective_mu = mu\n    \n    # Compute ratio\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine base factor based on iteration\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to make updates diminish over time\n    t = tau(k, c, p)\n    factor = max(base_factor - t, 1.05)\n    \n    # Update decision\n    if ratio > effective_mu:\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Bound rho for numerical stability\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use ratio as auxiliary value\n    aux = ratio\n    return new_rho, aux, mode\n\n```\nUnique approach: Modification:, [Fragment formatting error: 'metric_name'], NumPy-based implementation\n\n# Current Program\n```python\n# initial_program.py\n# This file is evolved by AlphaEvolve\n# Only update_rho (and helpers) should be modified\n\nimport numpy as np\n\n\ndef tau(k, c=1.0, p=1.2):\n    \"\"\"\n    Diminishing step size, must be summable.\n    AlphaEvolve is allowed to change this.\n    \"\"\"\n    return c / ((k + 1) ** p)\n\n\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of primal to dual residual\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration and ratio\n    # Early iterations: more aggressive updates\n    if k < 5:\n        # Very aggressive in the first few iterations\n        base_factor = 1.8\n    elif k < 15:\n        # Moderate updates\n        base_factor = 1.4\n    else:\n        # Conservative updates for stability\n        base_factor = 1.1\n    \n    # Use tau to make updates diminish over time\n    t = tau(k, c, p)\n    # The factor should decrease as iterations increase\n    factor = base_factor - 0.5 * t\n    # Ensure factor is at least 1.05\n    factor = max(factor, 1.05)\n    \n    # Check if we need to update\n    # Use a dynamic mu that becomes stricter over time\n    # Early iterations: allow more imbalance to explore\n    if k < 10:\n        effective_mu = 4.0\n    else:\n        effective_mu = mu\n    \n    if ratio > effective_mu:\n        # Primal residual is too large: increase rho\n        # Make the update proportional to the square root of the ratio, but bounded\n        # This helps to adjust more when the imbalance is larger\n        adjustment = min(np.sqrt(ratio), factor)\n        new_rho = rho * adjustment\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Dual residual is too large: decrease rho\n        adjustment = min(np.sqrt(1.0 / ratio), factor)\n        new_rho = rho / adjustment\n        mode = \"div\"\n    else:\n        # Balanced residuals\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to maintain numerical stability\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    # Use log ratio as auxiliary information for better scaling\n    aux = np.log(ratio + 1e-16)\n    return new_rho, aux, mode\n\n```\n\n# Task\nSuggest improvements to the program that will improve its FITNESS SCORE.\nThe system maintains diversity across these dimensions: complexity, diversity\nDifferent solutions with similar fitness but different features are valuable.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.", "responses": ["Looking at the current program, I notice it has a fitness score of 0.0762, which is lower than the top-performing programs (0.0829). The current approach uses a dynamic `effective_mu` and adjusts the update factor based on iteration, but it seems to be less effective. Let's analyze:\n\n1. The top programs use a simpler approach with fixed `mu` and a base factor that decreases with iterations, and they use `tau` to make updates diminish over time.\n2. The current program uses a more complex adjustment: `adjustment = min(np.sqrt(ratio), factor)` which might be causing issues.\n3. Also, the auxiliary value is `np.log(ratio + 1e-16)` which might not be as informative.\n\nLet's simplify and align with the top-performing strategies. Specifically, I'll:\n1. Use both `r_ratio` and `s_ratio` for balanced decision making (like in Program D1)\n2. Use a fixed `mu` without dynamic adjustment for simplicity and better performance\n3. Use a base factor that decreases with iterations, and combine with `tau` to make updates diminish\n4. Ensure numerical stability with bounds\n\nHere are the changes:\n\n<<<<<<< SEARCH\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute the ratio of primal to dual residual\n    ratio = r_norm / max(s_norm, eps)\n    \n    # Determine update factor based on iteration and ratio\n    # Early iterations: more aggressive updates\n    if k < 5:\n        # Very aggressive in the first few iterations\n        base_factor = 1.8\n    elif k < 15:\n        # Moderate updates\n        base_factor = 1.4\n    else:\n        # Conservative updates for stability\n        base_factor = 1.1\n    \n    # Use tau to make updates diminish over time\n    t = tau(k, c, p)\n    # The factor should decrease as iterations increase\n    factor = base_factor - 0.5 * t\n    # Ensure factor is at least 1.05\n    factor = max(factor, 1.05)\n    \n    # Check if we need to update\n    # Use a dynamic mu that becomes stricter over time\n    # Early iterations: allow more imbalance to explore\n    if k < 10:\n        effective_mu = 4.0\n    else:\n        effective_mu = mu\n    \n    if ratio > effective_mu:\n        # Primal residual is too large: increase rho\n        # Make the update proportional to the square root of the ratio, but bounded\n        # This helps to adjust more when the imbalance is larger\n        adjustment = min(np.sqrt(ratio), factor)\n        new_rho = rho * adjustment\n        mode = \"mul\"\n    elif 1.0 / ratio > effective_mu:\n        # Dual residual is too large: decrease rho\n        adjustment = min(np.sqrt(1.0 / ratio), factor)\n        new_rho = rho / adjustment\n        mode = \"div\"\n    else:\n        # Balanced residuals\n        new_rho = rho\n        mode = \"keep\"\n    \n    # Clip rho to maintain numerical stability\n    rho_min = 1e-6\n    rho_max = 1e6\n    new_rho = max(rho_min, min(new_rho, rho_max))\n    \n    # Use log ratio as auxiliary information for better scaling\n    aux = np.log(ratio + 1e-16)\n    return new_rho, aux, mode\n=======\ndef update_rho(\n    rho,\n    k,\n    r_norm,\n    s_norm,\n    mu=3.0,\n    c=1.0,\n    p=1.2,\n    eps=1e-12,\n):\n    \"\"\"\n    Adaptive ADMM penalty update rule.\n\n    Inputs:\n        rho    : current penalty parameter\n        k      : iteration index\n        r_norm : ||primal residual||\n        s_norm : ||dual residual||\n    Outputs:\n        new_rho : updated rho\n        aux     : any auxiliary scalar (logged but not used)\n        mode    : string label (\"mul\", \"div\", \"keep\", etc.)\n\n    AlphaEvolve may change the internal logic,\n    but MUST respect the signature and return types.\n    \"\"\"\n    # Compute both ratios for balanced decision\n    r_ratio = r_norm / max(s_norm, eps)\n    s_ratio = s_norm / max(r_norm, eps)\n    \n    # Determine base factor based on iteration\n    # Early iterations: larger updates, later: smaller updates\n    if k < 5:\n        base_factor = 1.5\n    elif k < 20:\n        base_factor = 1.2\n    else:\n        base_factor = 1.1\n    \n    # Use tau to add diminishing component\n    t = tau(k, c, p)\n    # Adjust factor to decrease with iterations\n    factor = base_factor - t\n    # Ensure factor is at least 1.05 for meaningful updates\n    factor = max(factor, 1.05)\n    \n    # Check conditions using both ratios\n    if r_ratio > mu:\n        # Primal residual is too large relative to dual residual\n        new_rho = rho * factor\n        mode = \"mul\"\n    elif s_ratio > mu:\n        # Dual residual is too large relative to primal residual\n        new_rho = rho / factor\n        mode = \"div\"\n    else:\n        # Both residuals are balanced\n        new_rho = rho\n        mode = \"keep\"\n    \n    # For numerical stability, bound rho between 1e-6 and 1e6\n    new_rho = max(min(new_rho, 1e6), 1e-6)\n    \n    # Use the larger ratio as auxiliary information\n    aux = max(r_ratio, s_ratio)\n    return new_rho, aux, mode\n>>>>>>> REPLACE\n\nThis change simplifies the update strategy to match the top-performing programs, which have shown better fitness. Key improvements:\n1. Uses both `r_ratio` and `s_ratio` for more balanced decisions.\n2. Removes the dynamic `effective_mu` and uses a fixed `mu=3.0` as per the default.\n3. Uses a simpler factor calculation that decreases with iterations via `tau`.\n4. Removes the complex `adjustment = min(np.sqrt(ratio), factor)` which might cause instability.\n5. Changes auxiliary value to `max(r_ratio, s_ratio)` which is more informative than the log ratio.\n\nThis should lead to faster convergence and better numerical stability, aligning with the top performers."]}}, "artifacts_json": null, "artifact_dir": null, "embedding": null}